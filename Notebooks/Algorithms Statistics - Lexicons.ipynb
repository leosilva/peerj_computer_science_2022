{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4de6f0b",
   "metadata": {},
   "source": [
    "# Research Data for paper \"How accurate are developers' emotions inferred from social media?\"\n",
    "\n",
    "## Statistics - Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c0f62",
   "metadata": {},
   "source": [
    "This Notebook file contains the source codes for the statistics over the dataset used in the paper \"How accurate are developers' emotions inferred from social media?\".\n",
    "\n",
    "Due to participants' data privacy, we do not present any identifiable data here, such as participants' Twitter account or text publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ccd27582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from dateutil.relativedelta import *\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "import sklearn.metrics as me\n",
    "from collections import Counter\n",
    "import copy\n",
    "from scipy.stats import norm, skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0340e",
   "metadata": {},
   "source": [
    "## DATA READING\n",
    "\n",
    "The JSON file 'alldata.json' contains the data used in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6f14e441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(r'https://raw.githubusercontent.com/leosilva/jss_2021_paper/master/alldata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6475ca47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <td>2009-03-11 12:51:34</td>\n",
       "      <td>2008-06-17 14:52:40</td>\n",
       "      <td>2017-11-05 01:21:27</td>\n",
       "      <td>2009-09-27 00:22:22</td>\n",
       "      <td>2015-08-18 09:44:42</td>\n",
       "      <td>2007-12-02 18:59:26</td>\n",
       "      <td>2018-08-28 15:53:30</td>\n",
       "      <td>2012-03-19 11:54:15</td>\n",
       "      <td>2008-01-09 20:56:00</td>\n",
       "      <td>2009-08-02 15:11:05</td>\n",
       "      <td>2008-12-21 15:24:53</td>\n",
       "      <td>2010-07-30 18:14:56</td>\n",
       "      <td>2009-01-04 16:46:32</td>\n",
       "      <td>2013-10-30 12:34:50</td>\n",
       "      <td>2018-08-07 07:54:08</td>\n",
       "      <td>2010-01-29 13:40:07</td>\n",
       "      <td>2018-09-15 09:25:06</td>\n",
       "      <td>2009-08-28 21:11:31</td>\n",
       "      <td>2010-03-04 19:05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweets</th>\n",
       "      <td>[[102566, 2021-03-31T19:13:28, 26, -0.45880000...</td>\n",
       "      <td>[[108111, 2021-03-31T20:30:21, 27, -0.0258, ne...</td>\n",
       "      <td>[[113189, 2021-03-31T21:52:37, 28, 0.0, neu, n...</td>\n",
       "      <td>[[119977, 2021-03-31T21:31:58, 29, 0.5859, pos...</td>\n",
       "      <td>[[123576, 2021-03-31T09:36:24, 30, 0.610300000...</td>\n",
       "      <td>[[126748, 2021-03-31T22:18:50, 31, 0.248100000...</td>\n",
       "      <td>[[139947, 2021-03-31T23:34:40, 32, 0.198400000...</td>\n",
       "      <td>[[142861, 2021-03-31T23:12:55, 33, -0.34, neg,...</td>\n",
       "      <td>[[154027, 2021-03-31T23:30:22, 34, 0.7088, pos...</td>\n",
       "      <td>[[157011, 2021-03-31T19:13:22, 35, -0.40190000...</td>\n",
       "      <td>[[160069, 2021-03-30T12:47:49, 36, 0.1027, pos...</td>\n",
       "      <td>[[163576, 2021-03-31T18:48:36, 37, 0.296, pos,...</td>\n",
       "      <td>[[171161, 2021-03-31T23:11:12, 38, 0.7096, pos...</td>\n",
       "      <td>[[176593, 2021-03-31T16:06:49, 39, -0.37160000...</td>\n",
       "      <td>[[179579, 2021-03-31T18:09:10, 40, 0.0, neu, n...</td>\n",
       "      <td>[[184846, 2021-03-31T17:53:40, 41, -0.2023, ne...</td>\n",
       "      <td>[[191406, 2021-03-31T07:12:32, 42, 0.0, neu, n...</td>\n",
       "      <td>[[196544, 2021-03-31T23:47:03, 43, 0.6369, pos...</td>\n",
       "      <td>[[224369, 2021-03-31T23:57:17, 44, -0.70890000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigfive</th>\n",
       "      <td>[[4, 37, 43, 36, 24, 26, 26]]</td>\n",
       "      <td>[[3, 41, 43, 34, 22, 23, 27]]</td>\n",
       "      <td>[[2, 43, 46, 31, 24, 15, 28]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[9, 17, 33, 33, 22, 39, 30]]</td>\n",
       "      <td>[[1, 22, 33, 31, 20, 8, 31]]</td>\n",
       "      <td>[[14, 39, 49, 39, 28, 15, 32]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[6, 35, 35, 32, 26, 16, 34]]</td>\n",
       "      <td>[[5, 29, 45, 34, 35, 29, 35]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[7, 40, 46, 38, 22, 21, 37]]</td>\n",
       "      <td>[[8, 32, 46, 19, 18, 28, 38]]</td>\n",
       "      <td>[[10, 31, 36, 25, 33, 21, 39]]</td>\n",
       "      <td>[[11, 36, 45, 31, 31, 19, 40]]</td>\n",
       "      <td>[[12, 29, 41, 28, 22, 28, 41]]</td>\n",
       "      <td>[[13, 29, 43, 27, 23, 35, 42]]</td>\n",
       "      <td>[[15, 29, 45, 36, 27, 32, 43]]</td>\n",
       "      <td>[[16, 30, 35, 24, 20, 32, 44]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               26  \\\n",
       "participant_id                                                  1   \n",
       "created_at                                    2009-03-11 12:51:34   \n",
       "tweets          [[102566, 2021-03-31T19:13:28, 26, -0.45880000...   \n",
       "bigfive                             [[4, 37, 43, 36, 24, 26, 26]]   \n",
       "\n",
       "                                                               27  \\\n",
       "participant_id                                                  2   \n",
       "created_at                                    2008-06-17 14:52:40   \n",
       "tweets          [[108111, 2021-03-31T20:30:21, 27, -0.0258, ne...   \n",
       "bigfive                             [[3, 41, 43, 34, 22, 23, 27]]   \n",
       "\n",
       "                                                               28  \\\n",
       "participant_id                                                  3   \n",
       "created_at                                    2017-11-05 01:21:27   \n",
       "tweets          [[113189, 2021-03-31T21:52:37, 28, 0.0, neu, n...   \n",
       "bigfive                             [[2, 43, 46, 31, 24, 15, 28]]   \n",
       "\n",
       "                                                               29  \\\n",
       "participant_id                                               None   \n",
       "created_at                                    2009-09-27 00:22:22   \n",
       "tweets          [[119977, 2021-03-31T21:31:58, 29, 0.5859, pos...   \n",
       "bigfive                                                        []   \n",
       "\n",
       "                                                               30  \\\n",
       "participant_id                                                  4   \n",
       "created_at                                    2015-08-18 09:44:42   \n",
       "tweets          [[123576, 2021-03-31T09:36:24, 30, 0.610300000...   \n",
       "bigfive                             [[9, 17, 33, 33, 22, 39, 30]]   \n",
       "\n",
       "                                                               31  \\\n",
       "participant_id                                                  5   \n",
       "created_at                                    2007-12-02 18:59:26   \n",
       "tweets          [[126748, 2021-03-31T22:18:50, 31, 0.248100000...   \n",
       "bigfive                              [[1, 22, 33, 31, 20, 8, 31]]   \n",
       "\n",
       "                                                               32  \\\n",
       "participant_id                                                  6   \n",
       "created_at                                    2018-08-28 15:53:30   \n",
       "tweets          [[139947, 2021-03-31T23:34:40, 32, 0.198400000...   \n",
       "bigfive                            [[14, 39, 49, 39, 28, 15, 32]]   \n",
       "\n",
       "                                                               33  \\\n",
       "participant_id                                               None   \n",
       "created_at                                    2012-03-19 11:54:15   \n",
       "tweets          [[142861, 2021-03-31T23:12:55, 33, -0.34, neg,...   \n",
       "bigfive                                                        []   \n",
       "\n",
       "                                                               34  \\\n",
       "participant_id                                                  7   \n",
       "created_at                                    2008-01-09 20:56:00   \n",
       "tweets          [[154027, 2021-03-31T23:30:22, 34, 0.7088, pos...   \n",
       "bigfive                             [[6, 35, 35, 32, 26, 16, 34]]   \n",
       "\n",
       "                                                               35  \\\n",
       "participant_id                                                  8   \n",
       "created_at                                    2009-08-02 15:11:05   \n",
       "tweets          [[157011, 2021-03-31T19:13:22, 35, -0.40190000...   \n",
       "bigfive                             [[5, 29, 45, 34, 35, 29, 35]]   \n",
       "\n",
       "                                                               36  \\\n",
       "participant_id                                               None   \n",
       "created_at                                    2008-12-21 15:24:53   \n",
       "tweets          [[160069, 2021-03-30T12:47:49, 36, 0.1027, pos...   \n",
       "bigfive                                                        []   \n",
       "\n",
       "                                                               37  \\\n",
       "participant_id                                                  9   \n",
       "created_at                                    2010-07-30 18:14:56   \n",
       "tweets          [[163576, 2021-03-31T18:48:36, 37, 0.296, pos,...   \n",
       "bigfive                             [[7, 40, 46, 38, 22, 21, 37]]   \n",
       "\n",
       "                                                               38  \\\n",
       "participant_id                                                 10   \n",
       "created_at                                    2009-01-04 16:46:32   \n",
       "tweets          [[171161, 2021-03-31T23:11:12, 38, 0.7096, pos...   \n",
       "bigfive                             [[8, 32, 46, 19, 18, 28, 38]]   \n",
       "\n",
       "                                                               39  \\\n",
       "participant_id                                                 11   \n",
       "created_at                                    2013-10-30 12:34:50   \n",
       "tweets          [[176593, 2021-03-31T16:06:49, 39, -0.37160000...   \n",
       "bigfive                            [[10, 31, 36, 25, 33, 21, 39]]   \n",
       "\n",
       "                                                               40  \\\n",
       "participant_id                                                 12   \n",
       "created_at                                    2018-08-07 07:54:08   \n",
       "tweets          [[179579, 2021-03-31T18:09:10, 40, 0.0, neu, n...   \n",
       "bigfive                            [[11, 36, 45, 31, 31, 19, 40]]   \n",
       "\n",
       "                                                               41  \\\n",
       "participant_id                                                 13   \n",
       "created_at                                    2010-01-29 13:40:07   \n",
       "tweets          [[184846, 2021-03-31T17:53:40, 41, -0.2023, ne...   \n",
       "bigfive                            [[12, 29, 41, 28, 22, 28, 41]]   \n",
       "\n",
       "                                                               42  \\\n",
       "participant_id                                                 14   \n",
       "created_at                                    2018-09-15 09:25:06   \n",
       "tweets          [[191406, 2021-03-31T07:12:32, 42, 0.0, neu, n...   \n",
       "bigfive                            [[13, 29, 43, 27, 23, 35, 42]]   \n",
       "\n",
       "                                                               43  \\\n",
       "participant_id                                                 15   \n",
       "created_at                                    2009-08-28 21:11:31   \n",
       "tweets          [[196544, 2021-03-31T23:47:03, 43, 0.6369, pos...   \n",
       "bigfive                            [[15, 29, 45, 36, 27, 32, 43]]   \n",
       "\n",
       "                                                               44  \n",
       "participant_id                                                 16  \n",
       "created_at                                    2010-03-04 19:05:54  \n",
       "tweets          [[224369, 2021-03-31T23:57:17, 44, -0.70890000...  \n",
       "bigfive                            [[16, 30, 35, 24, 20, 32, 44]]  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c07a3357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY1_5_cat</th>\n",
       "      <th>Classification_PSY2_5_cat</th>\n",
       "      <th>Classification_PSY3_5_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102600</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102895</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103085</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103092</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103200</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY1_5_cat Classification_PSY2_5_cat  \\\n",
       "0  102600             Weak Negative             Weak Positive   \n",
       "1  102895             Weak Negative           Strong Negative   \n",
       "2  103085           Strong Negative           Strong Negative   \n",
       "3  103092             Weak Positive             Weak Positive   \n",
       "4  103200             Weak Positive             Weak Negative   \n",
       "\n",
       "  Classification_PSY3_5_cat  \n",
       "0                   Neutral  \n",
       "1           Strong Negative  \n",
       "2           Strong Negative  \n",
       "3             Weak Positive  \n",
       "4           Strong Negative  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi = pd.read_csv(r'https://raw.githubusercontent.com/leosilva/jss_2021_paper/master/analyzed_tweets_dataset1_first_round.csv')\n",
    "data_psi.columns = ['id',\n",
    "                    'Classification_PSY1_5_cat',\n",
    "                    'Classification_PSY2_5_cat',\n",
    "                    'Classification_PSY3_5_cat']\n",
    "data_psi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec8134e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY1_5_cat</th>\n",
       "      <th>Classification_PSY2_5_cat</th>\n",
       "      <th>Classification_PSY3_5_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140009</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Weak Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140363</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140622</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140710</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Weak Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141162</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY1_5_cat Classification_PSY2_5_cat  \\\n",
       "0  140009             Weak Negative             Weak Negative   \n",
       "1  140363                   Neutral                   Neutral   \n",
       "2  140622             Weak Positive             Weak Positive   \n",
       "3  140710                   Neutral                   Neutral   \n",
       "4  141162                   Neutral             Weak Positive   \n",
       "\n",
       "  Classification_PSY3_5_cat  \n",
       "0             Weak Positive  \n",
       "1                   Neutral  \n",
       "2             Weak Positive  \n",
       "3             Weak Positive  \n",
       "4             Weak Positive  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi_restantes = pd.read_csv(r'https://raw.githubusercontent.com/leosilva/jss_2021_paper/master/analyzed_tweets_dataset2_first_round.csv')\n",
    "data_psi_restantes.columns = ['id',\n",
    "                    'Classification_PSY1_5_cat',\n",
    "                    'Classification_PSY2_5_cat',\n",
    "                    'Classification_PSY3_5_cat']\n",
    "data_psi_restantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ac79d670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY_5_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102600</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103241</td>\n",
       "      <td>Weak Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103875</td>\n",
       "      <td>Weak Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104229</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104337</td>\n",
       "      <td>Weak Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY_5_cat\n",
       "0  102600                  Neutral\n",
       "1  103241            Weak Negative\n",
       "2  103875            Weak Positive\n",
       "3  104229                  Neutral\n",
       "4  104337            Weak Negative"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi_divergentes_resolvidos = pd.read_csv(r'https://raw.githubusercontent.com/leosilva/jss_2021_paper/master/analyzed_tweets_second_round.csv')\n",
    "data_psi_divergentes_resolvidos.columns = ['id', 'Classification_PSY_5_cat']\n",
    "data_psi_divergentes_resolvidos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0d3e0",
   "metadata": {},
   "source": [
    "## Dataframe preparation - Psychologists answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d2b0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_polatiries_to_3_categories(df, column):\n",
    "    conditions = [\n",
    "        (df['{}_5_cat'.format(column)] == 'Weak Positive'),\n",
    "        (df['{}_5_cat'.format(column)] == 'Strong Positive'),\n",
    "        (df['{}_5_cat'.format(column)] == 'Neutral'),\n",
    "        (df['{}_5_cat'.format(column)] == 'Weak Negative'),\n",
    "        (df['{}_5_cat'.format(column)] == 'Strong Negative')\n",
    "        ]\n",
    "\n",
    "    values = ['pos', 'pos', 'neu', 'neg', 'neg']\n",
    "\n",
    "    df['{}_3_cat'.format(column)] = np.select(conditions, values)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6d21dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY1_5_cat</th>\n",
       "      <th>Classification_PSY2_5_cat</th>\n",
       "      <th>Classification_PSY3_5_cat</th>\n",
       "      <th>Classification_PSY1_3_cat</th>\n",
       "      <th>Classification_PSY2_3_cat</th>\n",
       "      <th>Classification_PSY3_3_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102600</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102895</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103085</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103092</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103200</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Strong Negative</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY1_5_cat Classification_PSY2_5_cat  \\\n",
       "0  102600             Weak Negative             Weak Positive   \n",
       "1  102895             Weak Negative           Strong Negative   \n",
       "2  103085           Strong Negative           Strong Negative   \n",
       "3  103092             Weak Positive             Weak Positive   \n",
       "4  103200             Weak Positive             Weak Negative   \n",
       "\n",
       "  Classification_PSY3_5_cat Classification_PSY1_3_cat  \\\n",
       "0                   Neutral                       neg   \n",
       "1           Strong Negative                       neg   \n",
       "2           Strong Negative                       neg   \n",
       "3             Weak Positive                       pos   \n",
       "4           Strong Negative                       pos   \n",
       "\n",
       "  Classification_PSY2_3_cat Classification_PSY3_3_cat  \n",
       "0                       pos                       neu  \n",
       "1                       neg                       neg  \n",
       "2                       neg                       neg  \n",
       "3                       pos                       pos  \n",
       "4                       neg                       neg  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi = reduce_polatiries_to_3_categories(data_psi, 'Classification_PSY1')\n",
    "data_psi = reduce_polatiries_to_3_categories(data_psi, 'Classification_PSY2')\n",
    "data_psi = reduce_polatiries_to_3_categories(data_psi, 'Classification_PSY3')\n",
    "data_psi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "91470f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY1_5_cat</th>\n",
       "      <th>Classification_PSY2_5_cat</th>\n",
       "      <th>Classification_PSY3_5_cat</th>\n",
       "      <th>Classification_PSY1_3_cat</th>\n",
       "      <th>Classification_PSY2_3_cat</th>\n",
       "      <th>Classification_PSY3_3_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140009</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140363</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140622</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140710</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141162</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY1_5_cat Classification_PSY2_5_cat  \\\n",
       "0  140009             Weak Negative             Weak Negative   \n",
       "1  140363                   Neutral                   Neutral   \n",
       "2  140622             Weak Positive             Weak Positive   \n",
       "3  140710                   Neutral                   Neutral   \n",
       "4  141162                   Neutral             Weak Positive   \n",
       "\n",
       "  Classification_PSY3_5_cat Classification_PSY1_3_cat  \\\n",
       "0             Weak Positive                       neg   \n",
       "1                   Neutral                       neu   \n",
       "2             Weak Positive                       pos   \n",
       "3             Weak Positive                       neu   \n",
       "4             Weak Positive                       neu   \n",
       "\n",
       "  Classification_PSY2_3_cat Classification_PSY3_3_cat  \n",
       "0                       neg                       pos  \n",
       "1                       neu                       neu  \n",
       "2                       pos                       pos  \n",
       "3                       neu                       pos  \n",
       "4                       pos                       pos  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi_restantes = reduce_polatiries_to_3_categories(data_psi_restantes, 'Classification_PSY1')\n",
    "data_psi_restantes = reduce_polatiries_to_3_categories(data_psi_restantes, 'Classification_PSY2')\n",
    "data_psi_restantes = reduce_polatiries_to_3_categories(data_psi_restantes, 'Classification_PSY3')\n",
    "data_psi_restantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "87d44f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_polatiries_to_5_categories(df, column):\n",
    "    conditions = [\n",
    "        (df[column] == 'Weak Positive'),\n",
    "        (df[column] == 'Strong Positive'),\n",
    "        (df[column] == 'Neutral'),\n",
    "        (df[column] == 'Weak Negative'),\n",
    "        (df[column] == 'Strong Negative')\n",
    "        ]\n",
    "\n",
    "    values = ['w_pos', 's_pos', 'neu', 'w_neg', 's_neg']\n",
    "\n",
    "    df[column] = np.select(conditions, values)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "30ef8545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY1_5_cat</th>\n",
       "      <th>Classification_PSY2_5_cat</th>\n",
       "      <th>Classification_PSY3_5_cat</th>\n",
       "      <th>Classification_PSY1_3_cat</th>\n",
       "      <th>Classification_PSY2_3_cat</th>\n",
       "      <th>Classification_PSY3_3_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102600</td>\n",
       "      <td>w_neg</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102895</td>\n",
       "      <td>w_neg</td>\n",
       "      <td>s_neg</td>\n",
       "      <td>s_neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103085</td>\n",
       "      <td>s_neg</td>\n",
       "      <td>s_neg</td>\n",
       "      <td>s_neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103092</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103200</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>w_neg</td>\n",
       "      <td>s_neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY1_5_cat Classification_PSY2_5_cat  \\\n",
       "0  102600                     w_neg                     w_pos   \n",
       "1  102895                     w_neg                     s_neg   \n",
       "2  103085                     s_neg                     s_neg   \n",
       "3  103092                     w_pos                     w_pos   \n",
       "4  103200                     w_pos                     w_neg   \n",
       "\n",
       "  Classification_PSY3_5_cat Classification_PSY1_3_cat  \\\n",
       "0                       neu                       neg   \n",
       "1                     s_neg                       neg   \n",
       "2                     s_neg                       neg   \n",
       "3                     w_pos                       pos   \n",
       "4                     s_neg                       pos   \n",
       "\n",
       "  Classification_PSY2_3_cat Classification_PSY3_3_cat  \n",
       "0                       pos                       neu  \n",
       "1                       neg                       neg  \n",
       "2                       neg                       neg  \n",
       "3                       pos                       pos  \n",
       "4                       neg                       neg  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi = rename_polatiries_to_5_categories(data_psi, 'Classification_PSY1_5_cat')\n",
    "data_psi = rename_polatiries_to_5_categories(data_psi, 'Classification_PSY2_5_cat')\n",
    "data_psi = rename_polatiries_to_5_categories(data_psi, 'Classification_PSY3_5_cat')\n",
    "data_psi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f04a3a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY1_5_cat</th>\n",
       "      <th>Classification_PSY2_5_cat</th>\n",
       "      <th>Classification_PSY3_5_cat</th>\n",
       "      <th>Classification_PSY1_3_cat</th>\n",
       "      <th>Classification_PSY2_3_cat</th>\n",
       "      <th>Classification_PSY3_3_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140009</td>\n",
       "      <td>w_neg</td>\n",
       "      <td>w_neg</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140363</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140622</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140710</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141162</td>\n",
       "      <td>neu</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>w_pos</td>\n",
       "      <td>neu</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY1_5_cat Classification_PSY2_5_cat  \\\n",
       "0  140009                     w_neg                     w_neg   \n",
       "1  140363                       neu                       neu   \n",
       "2  140622                     w_pos                     w_pos   \n",
       "3  140710                       neu                       neu   \n",
       "4  141162                       neu                     w_pos   \n",
       "\n",
       "  Classification_PSY3_5_cat Classification_PSY1_3_cat  \\\n",
       "0                     w_pos                       neg   \n",
       "1                       neu                       neu   \n",
       "2                     w_pos                       pos   \n",
       "3                     w_pos                       neu   \n",
       "4                     w_pos                       neu   \n",
       "\n",
       "  Classification_PSY2_3_cat Classification_PSY3_3_cat  \n",
       "0                       neg                       pos  \n",
       "1                       neu                       neu  \n",
       "2                       pos                       pos  \n",
       "3                       neu                       pos  \n",
       "4                       pos                       pos  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi_restantes = rename_polatiries_to_5_categories(data_psi_restantes, 'Classification_PSY1_5_cat')\n",
    "data_psi_restantes = rename_polatiries_to_5_categories(data_psi_restantes, 'Classification_PSY2_5_cat')\n",
    "data_psi_restantes = rename_polatiries_to_5_categories(data_psi_restantes, 'Classification_PSY3_5_cat')\n",
    "data_psi_restantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bccede90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Classification_PSY_5_cat</th>\n",
       "      <th>Classification_PSY_3_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102600</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103241</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103875</td>\n",
       "      <td>Weak Positive</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104229</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104337</td>\n",
       "      <td>Weak Negative</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Classification_PSY_5_cat Classification_PSY_3_cat\n",
       "0  102600                  Neutral                      neu\n",
       "1  103241            Weak Negative                      neg\n",
       "2  103875            Weak Positive                      pos\n",
       "3  104229                  Neutral                      neu\n",
       "4  104337            Weak Negative                      neg"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_psi_divergentes_resolvidos = reduce_polatiries_to_3_categories(data_psi_divergentes_resolvidos, 'Classification_PSY')\n",
    "data_psi_divergentes_resolvidos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1fd3eb2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos    245\n",
      "neg    107\n",
      "neu    103\n",
      "Name: Classification_PSY1_3_cat, dtype: int64\n",
      "pos    57\n",
      "neg    25\n",
      "neu    23\n",
      "Name: Classification_PSY1_3_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_psi['Classification_PSY1_3_cat'].value_counts())\n",
    "print(data_psi_restantes['Classification_PSY1_3_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "490a8c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unanimous classification:  175\n",
      "Majority classification:  334\n",
      "Divergences:  51\n"
     ]
    }
   ],
   "source": [
    "# AGREEMENT CALCULATION AMONG THE THREE PSYCHOLOGISTS\n",
    "\n",
    "data_psi_resultante = pd.concat([data_psi, data_psi_restantes])\n",
    "data_psi_resultante.head()\n",
    "\n",
    "maioria = 0\n",
    "unanime = 0\n",
    "divergentes = 0\n",
    "\n",
    "for d in data_psi_resultante['id']:\n",
    "    pol = []\n",
    "    t = data_psi_resultante.query('id == {}'.format(d))\n",
    "    pol.append(t['Classification_PSY1_3_cat'].values[0])\n",
    "    pol.append(t['Classification_PSY2_3_cat'].values[0])\n",
    "    pol.append(t['Classification_PSY3_3_cat'].values[0])\n",
    "    c = dict(Counter(pol))\n",
    "    if len(c) == 3:\n",
    "        divergentes += 1\n",
    "    else:\n",
    "        for i in c.items():\n",
    "            if i[1] == 3:\n",
    "                unanime += 1\n",
    "            elif i[1] == 2:\n",
    "                maioria += 1\n",
    "            \n",
    "print('Unanimous classification: ', unanime)\n",
    "print('Majority classification: ', maioria)\n",
    "print('Divergences: ', divergentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d010b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A LIST WITH ALL TWEETS\n",
    "\n",
    "tweets = []\n",
    "\n",
    "for d in data:\n",
    "    if data[d]['bigfive']:\n",
    "        tweets.append(data[d]['tweets'])\n",
    "\n",
    "final_tweets = []\n",
    "for i in tweets:\n",
    "    final_tweets.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "91faf0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91632\n"
     ]
    }
   ],
   "source": [
    "print(len(final_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fc83b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, algs):\n",
    "    clean_df_columns = [\n",
    "        'created_at',\n",
    "        'id_user',\n",
    "        'final_score',\n",
    "        'final_polarity',\n",
    "        'vader_sentiment_analysis_score',\n",
    "        'vader_sentiment_analysis_polarity',\n",
    "        'vader_sentiment_analysis_polarity_5_cat',\n",
    "        'oplexicon_sentiment_analysis_score',\n",
    "        'oplexicon_sentiment_analysis_polarity',\n",
    "        'oplexicon_sentiment_analysis_polarity_5_cat',\n",
    "        'sentistrength_sentiment_analysis_score',\n",
    "        'sentistrength_sentiment_analysis_polarity',\n",
    "        'sentistrength_sentiment_analysis_polarity_5_cat',\n",
    "        'sentilexpt_sentiment_analysis_score',\n",
    "        'sentilexpt_sentiment_analysis_polarity',\n",
    "        'sentilexpt_sentiment_analysis_polarity_5_cat',\n",
    "        'liwc_sentiment_analysis_score',\n",
    "        'liwc_sentiment_analysis_polarity',\n",
    "        'liwc_sentiment_analysis_polarity_5_cat'\n",
    "        \n",
    "    ]\n",
    "    for alg in algs:\n",
    "        if alg == 'vader':\n",
    "            clean_df_columns.remove('vader_sentiment_analysis_score')\n",
    "            clean_df_columns.remove('vader_sentiment_analysis_polarity')\n",
    "            clean_df_columns.remove('vader_sentiment_analysis_polarity_5_cat')\n",
    "        elif alg == 'oplexicon':\n",
    "            clean_df_columns.remove('oplexicon_sentiment_analysis_score')\n",
    "            clean_df_columns.remove('oplexicon_sentiment_analysis_polarity')\n",
    "            clean_df_columns.remove('oplexicon_sentiment_analysis_polarity_5_cat')\n",
    "        elif alg == 'sentistrength':\n",
    "            clean_df_columns.remove('sentistrength_sentiment_analysis_score')\n",
    "            clean_df_columns.remove('sentistrength_sentiment_analysis_polarity')\n",
    "            clean_df_columns.remove('sentistrength_sentiment_analysis_polarity_5_cat')\n",
    "        elif alg == 'sentilexpt':\n",
    "            clean_df_columns.remove('sentilexpt_sentiment_analysis_score')\n",
    "            clean_df_columns.remove('sentilexpt_sentiment_analysis_polarity')\n",
    "            clean_df_columns.remove('sentilexpt_sentiment_analysis_polarity_5_cat')\n",
    "        elif alg == 'liwc':\n",
    "            clean_df_columns.remove('liwc_sentiment_analysis_score')\n",
    "            clean_df_columns.remove('liwc_sentiment_analysis_polarity')\n",
    "            clean_df_columns.remove('liwc_sentiment_analysis_polarity_5_cat')\n",
    "        \n",
    "    for c in clean_df_columns:\n",
    "        del df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "251308ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TWEETS DATAFRAME FOR A CERTAIN PARTICIPANT\n",
    "\n",
    "def create_tweets_pd(data, id_user):\n",
    "\n",
    "    tweets_pd = pd.DataFrame(data[id_user]['tweets'])\n",
    "    del tweets_pd[0]\n",
    "    del tweets_pd[1]\n",
    "    del tweets_pd[4]\n",
    "    del tweets_pd[5]\n",
    "    del tweets_pd[6]\n",
    "    del tweets_pd[18]\n",
    "    del tweets_pd[19]\n",
    "    del tweets_pd[20]\n",
    "    \n",
    "    tweets_pd.columns = [\"id\", \"id_str_twitter\", \"text\", \"created_at\", \"id_user\", \"vader_sentiment_analysis_score\", \"vader_sentiment_analysis_polarity\",\n",
    "                         \"oplexicon_sentiment_analysis_score\", \"oplexicon_sentiment_analysis_polarity\",\n",
    "                         \"sentistrength_sentiment_analysis_score\", \"sentistrength_sentiment_analysis_polarity\",\n",
    "                         \"sentilexpt_sentiment_analysis_score\", \"sentilexpt_sentiment_analysis_polarity\",\n",
    "                         \"liwc_sentiment_analysis_score\", \"liwc_sentiment_analysis_polarity\",\n",
    "                         \"final_score\", \"final_polarity\"]\n",
    " \n",
    "    return tweets_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d89ad966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME FOR ALL TWEETS\n",
    "\n",
    "def create_tweets_df(tweets):\n",
    "    df = pd.DataFrame(final_tweets)\n",
    "\n",
    "    df.columns = [\"id\", \"created_at\", \"id_user\", \"vader_sentiment_analysis_score\",\n",
    "                  \"vader_sentiment_analysis_polarity\", \"vader_sentiment_analysis_polarity_5_cat\", \n",
    "                  \"oplexicon_sentiment_analysis_score\", \"oplexicon_sentiment_analysis_polarity\",\n",
    "                  \"oplexicon_sentiment_analysis_polarity_5_cat\", \"sentistrength_sentiment_analysis_score\",\n",
    "                  \"sentistrength_sentiment_analysis_polarity\", \"sentistrength_sentiment_analysis_polarity_5_cat\",\n",
    "                  \"sentilexpt_sentiment_analysis_score\", \"sentilexpt_sentiment_analysis_polarity\", \n",
    "                  \"sentilexpt_sentiment_analysis_polarity_5_cat\", \"liwc_sentiment_analysis_score\",\n",
    "                  \"liwc_sentiment_analysis_polarity\", \"liwc_sentiment_analysis_polarity_5_cat\",\n",
    "                  \"final_score\", \"final_score_ensemble\", \"final_polarity\", \"final_polarity_ensemble\",\n",
    "                  \"text_updated\", \"is_retweet\", \"retweet_updated\"\n",
    "                 ]\n",
    "    \n",
    "    del df[\"text_updated\"]\n",
    "    del df[\"is_retweet\"]\n",
    "    del df[\"retweet_updated\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cccce907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tweets_by_manually_analyzed(df, data_psi, algs):\n",
    "    filtered_list = []\n",
    "    for d in df['id']:\n",
    "        if not (data_psi.loc[data_psi['id'] == d]).empty:\n",
    "            t_psi = data_psi.loc[data_psi['id'] == d]\n",
    "            t_o = df.loc[df['id'] == d]\n",
    "            if len(algs) > 1:\n",
    "                scores = []\n",
    "                mean = 0\n",
    "                pol = ''\n",
    "                for a in algs:\n",
    "                    scores.append(t_o[\"{}_sentiment_analysis_score\".format(a)].values[0])\n",
    "                    mean = np.mean(scores)\n",
    "                    if mean > 0.0:\n",
    "                        pol = 'pos'\n",
    "                    elif mean < 0.0:\n",
    "                        pol = 'neg'\n",
    "                    else:\n",
    "                        pol = 'neu'\n",
    "                dic = {\n",
    "                    'id': d,\n",
    "                    'analysis_score': mean,\n",
    "                    'analysis_polarity': pol,\n",
    "                    'Classification_PSY1_3_cat': t_psi['Classification_PSY1_3_cat'].values[0],\n",
    "                    'Classification_PSY2_3_cat': t_psi['Classification_PSY2_3_cat'].values[0],\n",
    "                    'Classification_PSY3_3_cat': t_psi['Classification_PSY3_3_cat'].values[0]\n",
    "                }\n",
    "                filtered_list.append(dic)\n",
    "            else:\n",
    "                dic = {\n",
    "                    'id': d,\n",
    "                    'analysis_score': t_o[t_o.keys()[1]].values[0],\n",
    "                    'analysis_polarity': t_o[t_o.keys()[2]].values[0],\n",
    "                    'Classification_PSY1_3_cat': t_psi['Classification_PSY1_3_cat'].values[0],\n",
    "                    'Classification_PSY2_3_cat': t_psi['Classification_PSY2_3_cat'].values[0],\n",
    "                    'Classification_PSY3_3_cat': t_psi['Classification_PSY3_3_cat'].values[0]\n",
    "                }\n",
    "                filtered_list.append(dic)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered_list)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c089d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_manual_polarities_3_cat(df, df_consolidated):\n",
    "    for d in df['id']:\n",
    "        df_c = df_consolidated['id'] == d\n",
    "        if df_c.any():\n",
    "            df.loc[df['id'] == d, 'manual_polarity_3_cat'] = df_consolidated[df_consolidated['id'] == d]['Classification_PSY_3_cat'].values[0]\n",
    "        pol = []\n",
    "        t = df.query('id == {}'.format(d))\n",
    "        pol.append(t['Classification_PSY1_3_cat'].values[0])\n",
    "        pol.append(t['Classification_PSY2_3_cat'].values[0])\n",
    "        pol.append(t['Classification_PSY3_3_cat'].values[0])\n",
    "        c = dict(Counter(pol))\n",
    "        for i in c.items():\n",
    "            if i[1] >= 2:\n",
    "                df.loc[df['id'] == d, 'manual_polarity_3_cat'] = i[0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4b78af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_manual_polarities_5_cat(df):\n",
    "    for d in df['id']:\n",
    "        pol = []\n",
    "        t = df.query('id == {}'.format(d))\n",
    "        pol.append(t['Classification_PSY1_5_cat'].values[0])\n",
    "        pol.append(t['Classification_PSY2_5_cat'].values[0])\n",
    "        pol.append(t['Classification_PSY3_5_cat'].values[0])\n",
    "        c = dict(Counter(pol))\n",
    "        for i in c.items():\n",
    "            if i[1] >= 2:\n",
    "                df.loc[df['id'] == d, 'manual_polarity_5_cat'] = i[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c1a3d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(x, col1, col2):\n",
    "    if x[col1] == 1 and x[col2] == 1:\n",
    "        return 'TP'\n",
    "    elif x[col1] == 1 and x[col2] == -1:\n",
    "        return 'FN'\n",
    "    elif x[col1] == -1 and x[col2] == 1:\n",
    "        return 'FP'\n",
    "    elif x[col1] == -1 and x[col2] == -1:\n",
    "        return 'TN'\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f7a1f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistics(df_n, manual_polarity_category, alg):\n",
    "    df_n['manual_prediction'] = df_n[manual_polarity_category].apply(lambda x: -1 if x == 'neg' else (1 if x == 'pos' else 0))\n",
    "    df_n['analysis_prediction'] = df_n['analysis_polarity'].apply(lambda x: -1 if x == 'neg' else (1 if x == 'pos' else 0))\n",
    "\n",
    "    df_n['accuracy'] = df_n.apply(lambda x: 1 if x['manual_prediction'] == x['analysis_prediction'] else 0, axis=1)\n",
    "\n",
    "    df_n['conf_matrix'] = df_n.apply(lambda x: conf_matrix(x, 'manual_prediction', 'analysis_prediction'), axis=1)\n",
    "\n",
    "    list_precision = []\n",
    "\n",
    "    conf_vals = df_n['conf_matrix'].value_counts().to_dict()\n",
    "    \n",
    "    if 'FP' not in conf_vals:\n",
    "        conf_vals['FP'] = 0\n",
    "    if 'TP' not in conf_vals:\n",
    "        conf_vals['TP'] = 0\n",
    "    if 'FN' not in conf_vals:\n",
    "        conf_vals['FN'] = 0    \n",
    "    if 'TN' not in conf_vals:\n",
    "        conf_vals['TN'] = 0\n",
    "\n",
    "    accuracy = (conf_vals['TP'] + conf_vals['TN']) / (conf_vals['TP'] + conf_vals['TN'] + conf_vals['FP'] + conf_vals['FN'])\n",
    "    \n",
    "    precision_pos = conf_vals['TP'] / (conf_vals['TP'] + conf_vals['FP'])\n",
    "\n",
    "    recall_pos = conf_vals['TP'] / (conf_vals['TP'] + conf_vals['FN'])\n",
    "    f1_score_pos = 2*precision_pos*recall_pos / (precision_pos + recall_pos)\n",
    "\n",
    "    precision_neg = conf_vals['TN'] / (conf_vals['TN'] + conf_vals['FN'])\n",
    "    recall_neg = conf_vals['TN'] / (conf_vals['TN'] + conf_vals['FP'])\n",
    "    f1_score_neg = 2*precision_neg*recall_neg / (precision_neg + recall_neg)\n",
    "    \n",
    "    lexicon = alg[0] if len(alg) == 1 else \" + \".join(alg)\n",
    "\n",
    "    d = {\n",
    "        'Sentiment Lexicon': lexicon,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision - Positive': precision_pos,\n",
    "        'Recall - Positive': recall_pos,\n",
    "        'F1-Score - Positive': f1_score_pos,\n",
    "        'Precision - Negative': precision_neg,\n",
    "        'Recall - Negative': recall_neg,\n",
    "        'F1-Score - Negative': f1_score_neg,\n",
    "        'F1-Score - Average': (f1_score_pos + f1_score_neg) / 2\n",
    "    }\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "457e9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.DataFrame(columns=['Sentiment Lexicon', 'Accuracy', 'Precision - Positive', \n",
    "                                'Recall - Positive', 'F1-Score - Positive',\n",
    "                                'Precision - Negative', \n",
    "                                'Recall - Negative', 'F1-Score - Negative'\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9927491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = [] # lista que guarda a combinacao de todos os algoritmos\n",
    "\n",
    "def combinations(target,data):\n",
    "    for i in range(len(data)):\n",
    "        new_target = copy.copy(target)\n",
    "        new_data = copy.copy(data)\n",
    "        new_target.append(data[i])\n",
    "        new_data = data[i+1:]\n",
    "        combs.append(new_target)\n",
    "        combinations(new_target, new_data)\n",
    "\n",
    "target = []\n",
    "alg = [\n",
    "       'vader',\n",
    "       'oplexicon',\n",
    "       'sentistrength',\n",
    "       'sentilexpt',\n",
    "       'liwc'\n",
    "      ]\n",
    "combinations(target, alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c3af7",
   "metadata": {},
   "source": [
    "## METRICS CALCULATION FOR PSYCHOLIGISTS MANUAL ANALYSIS VERSUS ALL LEXICON ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec9436ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# MANUAL X ALL LEXICONS\n",
    "# ---------------------\n",
    "\n",
    "for a in combs:\n",
    "    df = create_tweets_df(final_tweets)\n",
    "    clean_df(df, a)\n",
    "    \n",
    "    df_n = filter_tweets_by_manually_analyzed(df, data_psi, a)\n",
    "    df_n = fill_manual_polarities_3_cat(df_n, data_psi_divergentes_resolvidos)\n",
    "    \n",
    "    df_res = filter_tweets_by_manually_analyzed(df, data_psi_restantes, a)\n",
    "    df_res = fill_manual_polarities_3_cat(df_res, data_psi_divergentes_resolvidos)\n",
    "    \n",
    "    df_n = pd.concat([df_n, df_res])\n",
    "    \n",
    "    d = perform_statistics(df_n, 'manual_polarity_3_cat', a)\n",
    "    rdf = rdf.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cfe085b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment Lexicon</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision - Positive</th>\n",
       "      <th>Recall - Positive</th>\n",
       "      <th>F1-Score - Positive</th>\n",
       "      <th>Precision - Negative</th>\n",
       "      <th>Recall - Negative</th>\n",
       "      <th>F1-Score - Negative</th>\n",
       "      <th>F1-Score - Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vader</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.745946</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.561151</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.654830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vader + oplexicon</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.721030</td>\n",
       "      <td>0.740088</td>\n",
       "      <td>0.730435</td>\n",
       "      <td>0.562963</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.640580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vader + oplexicon + sentistrength</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.657609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vader + oplexicon + sentistrength + sentilexpt</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.662770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vader + oplexicon + sentistrength + sentilexpt...</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.572414</td>\n",
       "      <td>0.588652</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.668259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vader + oplexicon + sentistrength + liwc</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.585185</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.568345</td>\n",
       "      <td>0.664651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vader + oplexicon + sentilexpt</td>\n",
       "      <td>0.676630</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.730435</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.576512</td>\n",
       "      <td>0.657487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vader + oplexicon + sentilexpt + liwc</td>\n",
       "      <td>0.676166</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.740125</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.588652</td>\n",
       "      <td>0.570447</td>\n",
       "      <td>0.655286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vader + oplexicon + liwc</td>\n",
       "      <td>0.664083</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.639531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vader + sentistrength</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.581132</td>\n",
       "      <td>0.662980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vader + sentistrength + sentilexpt</td>\n",
       "      <td>0.692098</td>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.732456</td>\n",
       "      <td>0.747204</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.625899</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>0.676738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vader + sentistrength + sentilexpt + liwc</td>\n",
       "      <td>0.702350</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.747934</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.624113</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.683700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vader + sentistrength + liwc</td>\n",
       "      <td>0.691689</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.742616</td>\n",
       "      <td>0.753747</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.587814</td>\n",
       "      <td>0.670780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vader + sentilexpt</td>\n",
       "      <td>0.678873</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.699074</td>\n",
       "      <td>0.725962</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.669103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vader + sentilexpt + liwc</td>\n",
       "      <td>0.683377</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.645390</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.669746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vader + liwc</td>\n",
       "      <td>0.662088</td>\n",
       "      <td>0.754808</td>\n",
       "      <td>0.685590</td>\n",
       "      <td>0.718535</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.647928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oplexicon</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.590906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oplexicon + sentistrength</td>\n",
       "      <td>0.693811</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.770732</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.654974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oplexicon + sentistrength + sentilexpt</td>\n",
       "      <td>0.696319</td>\n",
       "      <td>0.744076</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.760291</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.673032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>oplexicon + sentistrength + sentilexpt + liwc</td>\n",
       "      <td>0.700272</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.572519</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.672428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oplexicon + sentistrength + liwc</td>\n",
       "      <td>0.682065</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.759754</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.644937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>oplexicon + sentilexpt</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>0.740541</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>0.645071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>oplexicon + sentilexpt + liwc</td>\n",
       "      <td>0.674931</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.746781</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.646467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>oplexicon + liwc</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.741053</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.449612</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.613204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sentistrength</td>\n",
       "      <td>0.759825</td>\n",
       "      <td>0.819876</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.604317</td>\n",
       "      <td>0.715951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sentistrength + sentilexpt</td>\n",
       "      <td>0.735915</td>\n",
       "      <td>0.779006</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.644550</td>\n",
       "      <td>0.717233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentistrength + sentilexpt + liwc</td>\n",
       "      <td>0.727528</td>\n",
       "      <td>0.778723</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.790497</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.610442</td>\n",
       "      <td>0.700469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sentistrength + liwc</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.813636</td>\n",
       "      <td>0.797327</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.591928</td>\n",
       "      <td>0.694628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sentilexpt</td>\n",
       "      <td>0.692982</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.709924</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.631068</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.688281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sentilexpt + liwc</td>\n",
       "      <td>0.688623</td>\n",
       "      <td>0.753555</td>\n",
       "      <td>0.753555</td>\n",
       "      <td>0.753555</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.665395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>liwc</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.659856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Sentiment Lexicon  Accuracy  \\\n",
       "0                                               vader  0.666667   \n",
       "1                                   vader + oplexicon  0.663043   \n",
       "2                   vader + oplexicon + sentistrength  0.682540   \n",
       "3      vader + oplexicon + sentistrength + sentilexpt  0.685333   \n",
       "4   vader + oplexicon + sentistrength + sentilexpt...  0.691517   \n",
       "5            vader + oplexicon + sentistrength + liwc  0.692308   \n",
       "6                      vader + oplexicon + sentilexpt  0.676630   \n",
       "7               vader + oplexicon + sentilexpt + liwc  0.676166   \n",
       "8                            vader + oplexicon + liwc  0.664083   \n",
       "9                               vader + sentistrength  0.682857   \n",
       "10                 vader + sentistrength + sentilexpt  0.692098   \n",
       "11          vader + sentistrength + sentilexpt + liwc  0.702350   \n",
       "12                       vader + sentistrength + liwc  0.691689   \n",
       "13                                 vader + sentilexpt  0.678873   \n",
       "14                          vader + sentilexpt + liwc  0.683377   \n",
       "15                                       vader + liwc  0.662088   \n",
       "16                                          oplexicon  0.635688   \n",
       "17                          oplexicon + sentistrength  0.693811   \n",
       "18             oplexicon + sentistrength + sentilexpt  0.696319   \n",
       "19      oplexicon + sentistrength + sentilexpt + liwc  0.700272   \n",
       "20                   oplexicon + sentistrength + liwc  0.682065   \n",
       "21                             oplexicon + sentilexpt  0.666667   \n",
       "22                      oplexicon + sentilexpt + liwc  0.674931   \n",
       "23                                   oplexicon + liwc  0.655462   \n",
       "24                                      sentistrength  0.759825   \n",
       "25                         sentistrength + sentilexpt  0.735915   \n",
       "26                  sentistrength + sentilexpt + liwc  0.727528   \n",
       "27                               sentistrength + liwc  0.729167   \n",
       "28                                         sentilexpt  0.692982   \n",
       "29                                  sentilexpt + liwc  0.688623   \n",
       "30                                               liwc  0.703180   \n",
       "\n",
       "    Precision - Positive  Recall - Positive  F1-Score - Positive  \\\n",
       "0               0.745946           0.693467             0.718750   \n",
       "1               0.721030           0.740088             0.730435   \n",
       "2               0.737705           0.762712             0.750000   \n",
       "3               0.753191           0.746835             0.750000   \n",
       "4               0.762295           0.750000             0.756098   \n",
       "5               0.749020           0.773279             0.760956   \n",
       "6               0.746667           0.730435             0.738462   \n",
       "7               0.754237           0.726531             0.740125   \n",
       "8               0.733607           0.733607             0.733607   \n",
       "9               0.760563           0.729730             0.744828   \n",
       "10              0.762557           0.732456             0.747204   \n",
       "11              0.773504           0.747934             0.760504   \n",
       "12              0.765217           0.742616             0.753747   \n",
       "13              0.755000           0.699074             0.725962   \n",
       "14              0.770642           0.705882             0.736842   \n",
       "15              0.754808           0.685590             0.718535   \n",
       "16              0.691489           0.764706             0.726257   \n",
       "17              0.734884           0.810256             0.770732   \n",
       "18              0.744076           0.777228             0.760291   \n",
       "19              0.764706           0.771186             0.767932   \n",
       "20              0.734127           0.787234             0.759754   \n",
       "21              0.724868           0.740541             0.732620   \n",
       "22              0.743590           0.750000             0.746781   \n",
       "23              0.712551           0.771930             0.741053   \n",
       "24              0.819876           0.835443             0.827586   \n",
       "25              0.779006           0.801136             0.789916   \n",
       "26              0.778723           0.802632             0.790497   \n",
       "27              0.781659           0.813636             0.797327   \n",
       "28              0.744000           0.709924             0.726562   \n",
       "29              0.753555           0.753555             0.753555   \n",
       "30              0.746269           0.819672             0.781250   \n",
       "\n",
       "    Precision - Negative  Recall - Negative  F1-Score - Negative  \\\n",
       "0               0.561151           0.624000             0.590909   \n",
       "1               0.562963           0.539007             0.550725   \n",
       "2               0.582090           0.549296             0.565217   \n",
       "3               0.571429           0.579710             0.575540   \n",
       "4               0.572414           0.588652             0.580420   \n",
       "5               0.585185           0.552448             0.568345   \n",
       "6               0.566434           0.586957             0.576512   \n",
       "7               0.553333           0.588652             0.570447   \n",
       "8               0.545455           0.545455             0.545455   \n",
       "9               0.562044           0.601562             0.581132   \n",
       "10              0.587838           0.625899             0.606272   \n",
       "11              0.590604           0.624113             0.606897   \n",
       "12              0.573427           0.602941             0.587814   \n",
       "13              0.580645           0.647482             0.612245   \n",
       "14              0.565217           0.645390             0.602649   \n",
       "15              0.538462           0.622222             0.577320   \n",
       "16              0.506173           0.414141             0.455556   \n",
       "17              0.597826           0.491071             0.539216   \n",
       "18              0.608696           0.564516             0.585774   \n",
       "19              0.581395           0.572519             0.576923   \n",
       "20              0.568966           0.496241             0.530120   \n",
       "21              0.567568           0.547826             0.557522   \n",
       "22              0.550388           0.541985             0.546154   \n",
       "23              0.527273           0.449612             0.485356   \n",
       "24              0.617647           0.591549             0.604317   \n",
       "25              0.660194           0.629630             0.644550   \n",
       "26              0.628099           0.593750             0.610442   \n",
       "27              0.616822           0.568966             0.591928   \n",
       "28              0.631068           0.670103             0.650000   \n",
       "29              0.577236           0.577236             0.577236   \n",
       "30              0.597561           0.490000             0.538462   \n",
       "\n",
       "    F1-Score - Average  \n",
       "0             0.654830  \n",
       "1             0.640580  \n",
       "2             0.657609  \n",
       "3             0.662770  \n",
       "4             0.668259  \n",
       "5             0.664651  \n",
       "6             0.657487  \n",
       "7             0.655286  \n",
       "8             0.639531  \n",
       "9             0.662980  \n",
       "10            0.676738  \n",
       "11            0.683700  \n",
       "12            0.670780  \n",
       "13            0.669103  \n",
       "14            0.669746  \n",
       "15            0.647928  \n",
       "16            0.590906  \n",
       "17            0.654974  \n",
       "18            0.673032  \n",
       "19            0.672428  \n",
       "20            0.644937  \n",
       "21            0.645071  \n",
       "22            0.646467  \n",
       "23            0.613204  \n",
       "24            0.715951  \n",
       "25            0.717233  \n",
       "26            0.700469  \n",
       "27            0.694628  \n",
       "28            0.688281  \n",
       "29            0.665395  \n",
       "30            0.659856  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0e02a46a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean - Precision POS:  0.751592\n",
      "Mean - Precision NEG:  0.578568\n",
      "Mean - Recall POS:  0.755139\n",
      "Mean - Recall NEG:  0.571708\n",
      "Mean - F1-Score POS:  0.752844\n",
      "Mean - F1-Score NEG:  0.573918\n",
      "Mean - Accuracy:  0.688195\n",
      "Mean - F1-Score - Average:  0.663381\n"
     ]
    }
   ],
   "source": [
    "print('Mean - Precision POS: ', round(np.mean(rdf['Precision - Positive']), 6))\n",
    "print('Mean - Precision NEG: ', round(np.mean(rdf['Precision - Negative']), 6))\n",
    "print('Mean - Recall POS: ', round(np.mean(rdf['Recall - Positive']), 6))\n",
    "print('Mean - Recall NEG: ', round(np.mean(rdf['Recall - Negative']), 6))\n",
    "print('Mean - F1-Score POS: ', round(np.mean(rdf['F1-Score - Positive']), 6))\n",
    "print('Mean - F1-Score NEG: ', round(np.mean(rdf['F1-Score - Negative']), 6))\n",
    "print('Mean - Accuracy: ', round(np.mean(rdf['Accuracy']), 6))\n",
    "print('Mean - F1-Score - Average: ', round(np.mean(rdf['F1-Score - Average']), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "489a75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD - Precision POS:  0.023252\n",
      "STD - Precision NEG:  0.031256\n",
      "STD - Recall POS:  0.0377\n",
      "STD - Recall NEG:  0.057243\n",
      "STD - F1-Score POS:  0.024498\n",
      "STD - F1-Score NEG:  0.039056\n",
      "STD - Accuracy:  0.024562\n",
      "STD - F1-Score - Average:  0.025342\n"
     ]
    }
   ],
   "source": [
    "print('STD - Precision POS: ', round(np.std(rdf['Precision - Positive']), 6))\n",
    "print('STD - Precision NEG: ', round(np.std(rdf['Precision - Negative']), 6))\n",
    "print('STD - Recall POS: ', round(np.std(rdf['Recall - Positive']), 6))\n",
    "print('STD - Recall NEG: ', round(np.std(rdf['Recall - Negative']), 6))\n",
    "print('STD - F1-Score POS: ', round(np.std(rdf['F1-Score - Positive']), 6))\n",
    "print('STD - F1-Score NEG: ', round(np.std(rdf['F1-Score - Negative']), 6))\n",
    "print('STD - Accuracy: ', round(np.std(rdf['Accuracy']), 6))\n",
    "print('STD - F1-Score - Average: ', round(np.std(rdf['F1-Score - Average']), 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
